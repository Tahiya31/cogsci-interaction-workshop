# cogsci-interaction-workshop: putting interaction center-stage 
Python based tutorials for interaction research data analysis.

# [Workshop Proposal](https://escholarship.org/content/qt8571r2dz/qt8571r2dz.pdf)


### Tutorials

1. [Tutorial 1](https://drive.google.com/file/d/11gSLOujqwAhY9jE3URm5C34NdEiOvFUL/view?usp=sharing) walks through how to use OpenPose on video recordings to extract body pose information.
2. [Tutorial 2](https://drive.google.com/file/d/1PXNbUenfNRRzxGr65sObsIIdXNHUDPpy/view?usp=sharing) walks through how to use OpenSMILE on audio recordings to extract audio feature information.
3. [Tutorial 3](https://drive.google.com/file/d/1zsZPpRS5cTosTDgdJ1pzHO7KtscpSQ49/view?usp=sharing) walks through how to use Whisper on audio recordings to get transcript from audio.


### How to start

1. Click on one of the tutorials and open it in Google Colab.
2. Click on 'File' in top-menu and save a copy to your own drive to make changes to the notebook.
3. Open the left menu and click on the folder icon. Here, you can create folders store your input and output files.

### Video Walk-through

* [Walk through tutorial 1 on OpenPose.](https://youtu.be/0irM1VRuB6Q)
* [Walk through tutorial 2 on OpenSMILE.](https://youtu.be/rasNA8x952c)
* [Walk through tutorial 3 on whisper.](https://youtu.be/SPu5x7J61lM)

### Feedback

We are building a complete set of resources and toolbox for supporting multimodality in interaction research and we would love to hear from you! Please share what other tools might be useful for interaction research and should be included here.

### Acknowledgments

We thank the authors of OpenPose, OpenSMILE, and whisper for their amazing research and sharing the works as open-source tools. If you find these tools useful in your reserach, please cite the original research papers.
